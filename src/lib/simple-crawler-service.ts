// è½»é‡çº§ç½‘é¡µçˆ¬è™«æœåŠ¡ - æ— éœ€Puppeteerï¼ŒåŸºäºfetchå’Œcheerio
// é€‚åˆçˆ¬å–é™æ€å†…å®¹ï¼Œæˆæœ¬ä½ï¼Œéƒ¨ç½²ç®€å•

export interface CrawledArticle {
  title: string
  url: string
  source: string
  description?: string
  publishDate?: string
  author?: string
  relevanceScore?: number
}

export interface NewsSource {
  name: string
  searchUrl: string
  headers?: Record<string, string>
  parseMethod: 'rss' | 'html' | 'api'
  selectors?: {
    articles: string
    title: string
    link: string
    description?: string
    date?: string
    author?: string
  }
  rateLimit: number
}

// é¢„å®šä¹‰çš„æ–°é—»æºï¼ˆRSS feedså’Œå¼€æ”¾APIï¼‰
const NEWS_SOURCES: NewsSource[] = [
  {
    name: 'Science Daily RSS',
    searchUrl: 'https://www.sciencedaily.com/rss/all.xml',
    parseMethod: 'rss',
    rateLimit: 2000
  },
  {
    name: 'Nature News RSS', 
    searchUrl: 'https://www.nature.com/nature.rss',
    parseMethod: 'rss',
    rateLimit: 1500
  },
  {
    name: 'Science Magazine RSS',
    searchUrl: 'https://science.org/rss/news_current.xml',
    parseMethod: 'rss',
    rateLimit: 1500
  },
  {
    name: 'MIT News RSS',
    searchUrl: 'https://news.mit.edu/rss/feed',
    parseMethod: 'rss',
    rateLimit: 2000
  },
  {
    name: 'Phys.org RSS',
    searchUrl: 'https://phys.org/rss-feed/',
    parseMethod: 'rss',
    rateLimit: 2000
  }
]

export class SimpleCrawlerService {
  private cache = new Map<string, { data: CrawledArticle[], timestamp: number }>()
  private cacheMinutes = 30

  async searchNews(query: string, maxResults = 20): Promise<CrawledArticle[]> {
    const cacheKey = `search:${query}:${maxResults}`
    
    // æ£€æŸ¥ç¼“å­˜
    const cached = this.getFromCache(cacheKey)
    if (cached) {
      console.log('ğŸ’¾ ä½¿ç”¨ç¼“å­˜ç»“æœ')
      return cached
    }

    const allArticles: CrawledArticle[] = []

    for (const source of NEWS_SOURCES) {
      try {
        console.log(`ğŸ“¡ æ­£åœ¨è·å– ${source.name}...`)
        const articles = await this.crawlFromSource(source, query)
        console.log(`  â””â”€ ${source.name} è¿”å› ${articles.length} ç¯‡æ–‡ç« `)
        allArticles.push(...articles)
        
        if (allArticles.length >= maxResults) break
        
        // é™åˆ¶è¯·æ±‚é¢‘ç‡
        await this.sleep(source.rateLimit)
        
      } catch (error) {
        console.error(`âŒ ${source.name} æ•°æ®è·å–å¤±è´¥:`, error)
        continue
      }
    }

    // å»é‡å’Œè´¨é‡è¿‡æ»¤
    const deduplicatedArticles = this.deduplicateArticles(allArticles)
    const qualityFiltered = this.filterHighQuality(deduplicatedArticles, query)
    
    // æŒ‰ç›¸å…³æ€§æ’åºå¹¶æ·»åŠ è°ƒè¯•ä¿¡æ¯
    const sortedArticles = this.rankByRelevance(qualityFiltered, query)
    const results = sortedArticles.slice(0, maxResults)
    
    // æ·»åŠ è°ƒè¯•æ—¥å¿—
    if (results.length > 0) {
      console.log('ğŸ¯ ç›¸å…³æ€§è¯„åˆ†è¯¦æƒ…:')
      results.forEach((article, index) => {
        const score = article.relevanceScore || 0
        console.log(`  ${index + 1}. [${score}åˆ†] ${article.title.substring(0, 60)}...`)
        console.log(`     æ¥æº: ${article.source} | ${article.url}`)
      })
      console.log(`ğŸ“Š è´¨é‡è¿‡æ»¤: ${allArticles.length} â†’ ${deduplicatedArticles.length} â†’ ${qualityFiltered.length} â†’ ${results.length}`)
    } else {
      console.log(`âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„æ–‡ç« `)
      console.log(`ğŸ“Š è´¨é‡è¿‡æ»¤: ${allArticles.length} â†’ ${deduplicatedArticles.length} â†’ ${qualityFiltered.length} â†’ ${results.length}`)
      console.log(`ğŸ” æŸ¥è¯¢è¯: "${query}"`)
    }
    
    // ç¼“å­˜ç»“æœ
    this.saveToCache(cacheKey, results)
    
    console.log(`âœ… æœç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° ${results.length} ç¯‡ç›¸å…³æ–‡ç« `)
    return results
  }

  private async crawlFromSource(source: NewsSource, query: string): Promise<CrawledArticle[]> {
    try {
      const response = await fetch(source.searchUrl, {
        headers: {
          'User-Agent': 'Mozilla/5.0 (compatible; Academic-Rating-Bot/1.0)',
          ...source.headers
        }
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const content = await response.text()

      switch (source.parseMethod) {
        case 'rss':
          return this.parseRSS(content, source.name, query)
        case 'api':
          return this.parseAPI(content, source.name, query)
        default:
          return []
      }
    } catch (error) {
      throw error
    }
  }

  private parseRSS(xml: string, sourceName: string, query: string): CrawledArticle[] {
    const articles: CrawledArticle[] = []
    
    try {
      // ç®€å•çš„XMLè§£æ - æå–itemå…ƒç´ 
      const itemRegex = /<item[^>]*>([\s\S]*?)<\/item>/gi
      const items = xml.match(itemRegex) || []
      
      for (const item of items.slice(0, 20)) { // é™åˆ¶æ¯ä¸ªæºæœ€å¤š20ç¯‡
        const title = this.extractXMLTag(item, 'title')
        const link = this.extractXMLTag(item, 'link')
        const description = this.extractXMLTag(item, 'description')
        const pubDate = this.extractXMLTag(item, 'pubDate')
        const author = this.extractXMLTag(item, 'author') || this.extractXMLTag(item, 'dc:creator')
        
        if (title && link) {
          const content = title + ' ' + (description || '')
          if (this.isRelevant(content, query)) {
            articles.push({
              title: this.cleanText(title),
              url: link,
              source: sourceName,
              description: description ? this.cleanText(description) : undefined,
              publishDate: pubDate ? this.normalizeDate(pubDate) : undefined,
              author: author ? this.cleanText(author) : undefined,
              relevanceScore: this.calculateRelevance(content, query)
            })
          }
        }
      }
    } catch (error) {
      console.error('RSSè§£æå¤±è´¥:', error)
    }
    
    return articles
  }

  private parseAPI(json: string, sourceName: string, query: string): CrawledArticle[] {
    const articles: CrawledArticle[] = []
    
    try {
      const data = JSON.parse(json)
      
      // æ ¹æ®ä¸åŒAPIæ ¼å¼å¤„ç†
      if (Array.isArray(data.articles)) {
        // NewsAPIæ ¼å¼
        for (const item of data.articles.slice(0, 10)) {
          if (this.isRelevant(item.title + ' ' + (item.description || ''), query)) {
            articles.push({
              title: this.cleanText(item.title),
              url: item.url,
              source: sourceName,
              description: item.description ? this.cleanText(item.description) : undefined,
              publishDate: item.publishedAt ? this.normalizeDate(item.publishedAt) : undefined,
              author: item.author || item.source?.name,
              relevanceScore: this.calculateRelevance(item.title + ' ' + (item.description || ''), query)
            })
          }
        }
      }
    } catch (error) {
      console.error('JSONè§£æå¤±è´¥:', error)
    }
    
    return articles
  }

  // å·¥å…·æ–¹æ³•
  private extractXMLTag(xml: string, tagName: string): string | undefined {
    const regex = new RegExp(`<${tagName}[^>]*>([\\s\\S]*?)<\\/${tagName}>`, 'i')
    const match = xml.match(regex)
    return match ? match[1].trim() : undefined
  }

  private cleanText(text: string): string {
    return text
      .replace(/<[^>]*>/g, '') // ç§»é™¤HTMLæ ‡ç­¾
      .replace(/&[^;]+;/g, ' ') // ç§»é™¤HTMLå®ä½“
      .replace(/\s+/g, ' ') // æ ‡å‡†åŒ–ç©ºç™½
      .trim()
      .substring(0, 500) // é™åˆ¶é•¿åº¦
  }

  private normalizeDate(dateString: string): string {
    try {
      const date = new Date(dateString)
      return date.toISOString().split('T')[0]
    } catch {
      return dateString.substring(0, 10)
    }
  }

  private isRelevant(content: string, query: string): boolean {
    const relevanceScore = this.calculateRelevance(content, query)
    // åªæœ‰å¾—åˆ†>0çš„æ‰ä¼šåœ¨ç»ˆç«¯æ˜¾ç¤º
    if (relevanceScore > 0) {
      console.log(`ğŸ” ç›¸å…³æ€§æ£€æŸ¥: "${content.substring(0, 50)}..." å¾—åˆ†: ${relevanceScore}`)
    }
    return relevanceScore >= 1
  }

  private calculateRelevance(content: string, query: string): number {
    const contentLower = content.toLowerCase()
    const queryLower = query.toLowerCase()
    
    // ç®€åŒ–ï¼šç›´æ¥åˆ†å‰²æŸ¥è¯¢è¯ï¼Œä¸è¿‡æ»¤å¸¸è§è¯
    const queryWords = queryLower.split(/\s+/)
      .filter(word => word.length > 2)
    
    if (queryWords.length === 0) return 0
    
    let totalScore = 0
    
    // 1. å®Œæ•´æŸ¥è¯¢åŒ¹é…
    if (contentLower.includes(queryLower)) {
      totalScore += 50
    }
    
    // 2. ç®€å•çš„å•è¯åŒ…å«æ£€æŸ¥ï¼ˆä¸ç”¨æ­£åˆ™ï¼‰
    for (const word of queryWords) {
      if (contentLower.includes(word)) {
        let wordScore = 10 // åŸºç¡€åˆ†æ•°
        
        // é•¿è¯åŠ æƒ
        if (word.length > 6) wordScore *= 1.5
        
        // ä¸“ä¸šæœ¯è¯­åŠ æƒ
        if (this.isTechnicalTerm(word)) {
          wordScore *= 2
        }
        
        totalScore += wordScore
      }
    }
    
    // 3. ç§‘å­¦å†…å®¹åŠ æƒ
    if (this.containsScientificContent(contentLower)) {
      totalScore *= 1.2
    }
    
    return Math.round(totalScore)
  }
  
  private extractPhrases(query: string): string[] {
    const words = query.split(/\s+/)
    const phrases: string[] = []
    
    // æå–2-4è¯ç»„åˆ
    for (let len = 2; len <= Math.min(4, words.length); len++) {
      for (let i = 0; i <= words.length - len; i++) {
        const phrase = words.slice(i, i + len).join(' ')
        if (phrase.length > 8) {
          phrases.push(phrase)
        }
      }
    }
    
    return phrases
  }
  
  private isTechnicalTerm(word: string): boolean {
    const technicalKeywords = [
      'research', 'study', 'analysis', 'method', 'technique', 'algorithm',
      'experiment', 'data', 'result', 'finding', 'discovery', 'breakthrough',
      'technology', 'innovation', 'development', 'application', 'material',
      'protein', 'cell', 'molecule', 'chemical', 'biological', 'physical',
      'quantum', 'nano', 'micro', 'macro', 'synthesis', 'characterization',
      'simulation', 'modeling', 'computational', 'theoretical', 'experimental',
      'ion', 'exchange', 'atomic', 'thin', 'clays', 'micas', 'hydration', 'solids'
    ]
    
    return technicalKeywords.some(term => word.includes(term) || term.includes(word))
  }
  
  private containsScientificContent(content: string): boolean {
    const scientificIndicators = [
      'nature', 'science', 'research', 'study', 'journal', 'paper', 'published',
      'university', 'laboratory', 'experiment', 'analysis', 'discovery',
      'breakthrough', 'innovation', 'technology', 'scientific', 'academic',
      'professor', 'researcher', 'scientist', 'phd', 'doi', 'arxiv'
    ]
    
    return scientificIndicators.some(indicator => content.includes(indicator))
  }
  
  private containsIrrelevantContent(content: string): boolean {
    const irrelevantIndicators = [
      'advertisement', 'promotion', 'sale', 'discount', 'buy now', 'click here',
      'celebrity', 'entertainment', 'gossip', 'sports score', 'weather',
      'horoscope', 'lottery', 'casino', 'betting', 'fashion', 'beauty tips',
      'recipe', 'cooking', 'travel deal', 'hotel', 'restaurant review'
    ]
    
    return irrelevantIndicators.some(indicator => content.includes(indicator))
  }
  
  private escapeRegex(string: string): string {
    return string.replace(/[.*+?^${}()|[\]\\]/g, '\\$&')
  }

  private rankByRelevance(articles: CrawledArticle[], query: string): CrawledArticle[] {
    return articles.sort((a, b) => {
      const scoreA = a.relevanceScore || this.calculateRelevance(a.title + ' ' + (a.description || ''), query)
      const scoreB = b.relevanceScore || this.calculateRelevance(b.title + ' ' + (b.description || ''), query)
      return scoreB - scoreA
    })
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }

  // å»é‡æ–¹æ³•
  private deduplicateArticles(articles: CrawledArticle[]): CrawledArticle[] {
    const seen = new Set<string>()
    const deduped: CrawledArticle[] = []
    
    for (const article of articles) {
      // ä½¿ç”¨æ ‡é¢˜å’ŒURLçš„ç»„åˆä½œä¸ºå”¯ä¸€æ ‡è¯†
      const key = `${article.title.toLowerCase().replace(/\s+/g, ' ').trim()}|${article.url}`
      
      if (!seen.has(key)) {
        seen.add(key)
        deduped.push(article)
      }
    }
    
    return deduped
  }
  
  // é«˜è´¨é‡å†…å®¹è¿‡æ»¤
  private filterHighQuality(articles: CrawledArticle[], query: string): CrawledArticle[] {
    return articles.filter(article => {
      // 1. åŸºæœ¬è´¨é‡æ£€æŸ¥
      if (!article.title || article.title.length < 10) return false
      if (!article.url || !article.url.startsWith('http')) return false
      
      // 2. æ ‡é¢˜è´¨é‡æ£€æŸ¥
      const title = article.title.toLowerCase()
      
      // è¿‡æ»¤æ˜æ˜¾æ— å…³çš„å†…å®¹
      const blacklistTerms = [
        'advertisement', 'sponsored', 'promo', 'sale', 'discount',
        'celebrity', 'gossip', 'entertainment', 'sports', 'weather',
        'horoscope', 'astrology', 'lottery', 'casino', 'betting',
        'fashion', 'beauty', 'makeup', 'recipe', 'cooking',
        'travel', 'hotel', 'restaurant', 'menu', 'diet'
      ]
      
      if (blacklistTerms.some(term => title.includes(term))) {
        return false
      }
      
      // 3. ç›¸å…³æ€§æ£€æŸ¥
      const relevanceScore = this.calculateRelevance(article.title + ' ' + (article.description || ''), query)
      article.relevanceScore = relevanceScore
      
      return relevanceScore >= 1 // æœ€ä½ç›¸å…³æ€§è¦æ±‚é™ä½åˆ°1åˆ†
    })
  }

  // ç¼“å­˜ç®¡ç†
  private getFromCache(key: string): CrawledArticle[] | null {
    const cached = this.cache.get(key)
    if (!cached) return null

    const now = Date.now()
    const ageMinutes = (now - cached.timestamp) / (1000 * 60)
    
    if (ageMinutes > this.cacheMinutes) {
      this.cache.delete(key)
      return null
    }
    
    return cached.data
  }

  private saveToCache(key: string, data: CrawledArticle[]): void {
    this.cache.set(key, {
      data,
      timestamp: Date.now()
    })
  }

  public clearCache(): void {
    this.cache.clear()
  }
}

// å•ä¾‹å®ä¾‹
export const simpleCrawlerService = new SimpleCrawlerService()

// å®šæœŸæ¸…ç†ç¼“å­˜
if (typeof window === 'undefined') {
  setInterval(() => {
    simpleCrawlerService.clearCache()
  }, 30 * 60 * 1000) // æ¯30åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
}