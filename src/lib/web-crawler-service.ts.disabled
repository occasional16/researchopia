// è‡ªå»ºçˆ¬è™«æœåŠ¡ - ä»å¤šä¸ªæ–°é—»ç½‘ç«™æŠ“å–è®ºæ–‡ç›¸å…³æŠ¥é“
// ä½¿ç”¨Puppeteerè¿›è¡Œç½‘é¡µçˆ¬å–ï¼Œæ”¯æŒJavaScriptæ¸²æŸ“çš„é¡µé¢

import puppeteer from 'puppeteer'
import * as cheerio from 'cheerio'

export interface CrawledArticle {
  title: string
  url: string
  source: string
  description?: string
  publishDate?: string
  author?: string
  content?: string
}

export interface CrawlTarget {
  name: string
  baseUrl: string
  searchUrl: string
  selectors: {
    articleLinks: string
    title: string
    description?: string
    date?: string
    author?: string
    content?: string
  }
  rateLimit: number // è¯·æ±‚é—´éš”(æ¯«ç§’)
}

// é¢„å®šä¹‰çš„çˆ¬å–ç›®æ ‡ç½‘ç«™
const CRAWL_TARGETS: CrawlTarget[] = [
  {
    name: 'Science Daily',
    baseUrl: 'https://www.sciencedaily.com',
    searchUrl: 'https://www.sciencedaily.com/search/?keyword={{QUERY}}',
    selectors: {
      articleLinks: '.search-result h3 a',
      title: 'h1',
      description: '.summary',
      date: '.date',
      author: '.author',
      content: '.story-content'
    },
    rateLimit: 2000
  },
  {
    name: 'EurekAlert',
    baseUrl: 'https://www.eurekalert.org',
    searchUrl: 'https://www.eurekalert.org/search?keywords={{QUERY}}',
    selectors: {
      articleLinks: '.release-title a',
      title: 'h1',
      description: '.release-summary',
      date: '.release-date',
      author: '.organization',
      content: '.release-content'
    },
    rateLimit: 1500
  },
  {
    name: 'Phys.org',
    baseUrl: 'https://phys.org',
    searchUrl: 'https://phys.org/search/?search={{QUERY}}',
    selectors: {
      articleLinks: '.news-link',
      title: 'h1.news-story-title',
      description: '.article-main p:first-of-type',
      date: '.article-byline time',
      author: '.article-byline .author',
      content: '.article-main'
    },
    rateLimit: 2500
  }
]

export class WebCrawlerService {
  private browser?: puppeteer.Browser
  private isInitialized = false

  async initialize() {
    if (this.isInitialized) return

    try {
      this.browser = await puppeteer.launch({
        headless: true,
        args: [
          '--no-sandbox',
          '--disable-setuid-sandbox',
          '--disable-dev-shm-usage',
          '--disable-accelerated-2d-canvas',
          '--disable-gpu',
          '--window-size=1920x1080'
        ]
      })
      this.isInitialized = true
      console.log('ğŸš€ ç½‘é¡µçˆ¬è™«å·²å¯åŠ¨')
    } catch (error) {
      console.error('âŒ çˆ¬è™«å¯åŠ¨å¤±è´¥:', error)
      throw new Error('çˆ¬è™«åˆå§‹åŒ–å¤±è´¥')
    }
  }

  async crawlArticles(query: string, maxResults = 20): Promise<CrawledArticle[]> {
    if (!this.isInitialized) {
      await this.initialize()
    }

    const allArticles: CrawledArticle[] = []
    
    for (const target of CRAWL_TARGETS) {
      try {
        console.log(`ğŸ” æ­£åœ¨æœç´¢ ${target.name}...`)
        const articles = await this.crawlFromSite(target, query, maxResults - allArticles.length)
        allArticles.push(...articles)
        
        // è¾¾åˆ°æœ€å¤§ç»“æœæ•°å°±åœæ­¢
        if (allArticles.length >= maxResults) break
        
        // è¯·æ±‚é—´éš”ï¼Œé¿å…è¢«å°
        await this.sleep(target.rateLimit)
        
      } catch (error) {
        console.error(`âš ï¸ ${target.name} çˆ¬å–å¤±è´¥:`, error)
        continue
      }
    }

    console.log(`âœ… çˆ¬å–å®Œæˆï¼Œå…±æ‰¾åˆ° ${allArticles.length} ç¯‡ç›¸å…³æ–‡ç« `)
    return allArticles
  }

  private async crawlFromSite(target: CrawlTarget, query: string, maxResults: number): Promise<CrawledArticle[]> {
    if (!this.browser) throw new Error('æµè§ˆå™¨æœªåˆå§‹åŒ–')

    const page = await this.browser.newPage()
    const articles: CrawledArticle[] = []

    try {
      // è®¾ç½®ç”¨æˆ·ä»£ç†ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
      await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
      
      // è®¿é—®æœç´¢é¡µé¢
      const searchUrl = target.searchUrl.replace('{{QUERY}}', encodeURIComponent(query))
      console.log(`ğŸ“¡ è®¿é—®: ${searchUrl}`)
      
      await page.goto(searchUrl, { 
        waitUntil: 'networkidle2',
        timeout: 30000 
      })

      // ç­‰å¾…å†…å®¹åŠ è½½
      await page.waitForTimeout(3000)

      // è·å–æ–‡ç« é“¾æ¥
      const articleLinks = await page.evaluate((selector, baseUrl) => {
        const links = Array.from(document.querySelectorAll(selector))
        return links.map((link: any) => {
          const href = link.href || link.getAttribute('href')
          return href?.startsWith('http') ? href : baseUrl + href
        }).filter(Boolean).slice(0, 10) // é™åˆ¶é“¾æ¥æ•°é‡
      }, target.selectors.articleLinks, target.baseUrl)

      console.log(`ğŸ”— æ‰¾åˆ° ${articleLinks.length} ä¸ªæ–‡ç« é“¾æ¥`)

      // çˆ¬å–æ¯ä¸ªæ–‡ç« çš„è¯¦ç»†å†…å®¹
      for (const articleUrl of articleLinks.slice(0, maxResults)) {
        try {
          const article = await this.crawlArticleDetails(page, target, articleUrl)
          if (article && this.isRelevant(article.title, query)) {
            articles.push(article)
          }
          
          // æ–‡ç« é—´éš”
          await this.sleep(1000)
          
        } catch (error) {
          console.error(`âš ï¸ æ–‡ç« çˆ¬å–å¤±è´¥ ${articleUrl}:`, error)
          continue
        }
      }

    } finally {
      await page.close()
    }

    return articles
  }

  private async crawlArticleDetails(page: puppeteer.Page, target: CrawlTarget, url: string): Promise<CrawledArticle | null> {
    try {
      await page.goto(url, { 
        waitUntil: 'networkidle2',
        timeout: 20000 
      })

      await page.waitForTimeout(2000)

      const article = await page.evaluate((selectors, sourceName, articleUrl) => {
        const getText = (selector: string) => {
          const element = document.querySelector(selector)
          return element?.textContent?.trim() || ''
        }

        const title = getText(selectors.title)
        if (!title) return null

        return {
          title,
          url: articleUrl,
          source: sourceName,
          description: selectors.description ? getText(selectors.description) : '',
          publishDate: selectors.date ? getText(selectors.date) : '',
          author: selectors.author ? getText(selectors.author) : '',
          content: selectors.content ? getText(selectors.content).substring(0, 1000) : ''
        }
      }, target.selectors, target.name, url)

      if (article) {
        console.log(`ğŸ“„ çˆ¬å–æˆåŠŸ: ${article.title.substring(0, 50)}...`)
      }

      return article
      
    } catch (error) {
      console.error(`âŒ çˆ¬å–æ–‡ç« è¯¦æƒ…å¤±è´¥ ${url}:`, error)
      return null
    }
  }

  // æ£€æŸ¥æ–‡ç« æ ‡é¢˜ä¸æŸ¥è¯¢çš„ç›¸å…³æ€§
  private isRelevant(title: string, query: string): boolean {
    const titleWords = title.toLowerCase().split(/\s+/)
    const queryWords = query.toLowerCase().split(/\s+/).filter(word => word.length > 3)
    
    let matches = 0
    for (const queryWord of queryWords) {
      if (titleWords.some(titleWord => titleWord.includes(queryWord) || queryWord.includes(titleWord))) {
        matches++
      }
    }
    
    // è‡³å°‘åŒ¹é…ä¸€ä¸ªå…³é”®è¯
    return matches > 0
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms))
  }

  async cleanup() {
    if (this.browser) {
      await this.browser.close()
      this.isInitialized = false
      console.log('ğŸ›‘ çˆ¬è™«å·²å…³é—­')
    }
  }
}

// å•ä¾‹å®ä¾‹
export const webCrawlerService = new WebCrawlerService()

// è¿›ç¨‹é€€å‡ºæ—¶æ¸…ç†èµ„æº
if (typeof window === 'undefined') {
  process.on('exit', () => webCrawlerService.cleanup())
  process.on('SIGINT', () => webCrawlerService.cleanup())
  process.on('SIGTERM', () => webCrawlerService.cleanup())
}